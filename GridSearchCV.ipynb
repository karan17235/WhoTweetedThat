{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning imports\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle Let's try and catch up live next week!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8746</td>\n",
       "      <td>Going to watch Grey's on the big screen - Thur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8746</td>\n",
       "      <td>@handle My pleasure Patrick....hope you are well!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              tweet\n",
       "0  8746     @handle Let's try and catch up live next week!\n",
       "1  8746  Going to watch Grey's on the big screen - Thur...\n",
       "2  8746  @handle My pleasure Patrick....hope you are well!"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv('../data/train_tweets.txt', sep=\"\\t\", header=None, names=[\"id\", \"tweet\"])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positve tagged sentences is:  91\n"
     ]
    }
   ],
   "source": [
    "user_id = df['id'][df.id == 8746]\n",
    "print('number of positve tagged sentences is:  {}'.format(len(user_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8746</td>\n",
       "      <td>@ let's try and catch up live next week!</td>\n",
       "      <td>9</td>\n",
       "      <td>[@, let's, try, catch, live, next, week!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8746</td>\n",
       "      <td>going to watch grey's on the big screen - thur...</td>\n",
       "      <td>11</td>\n",
       "      <td>[going, watch, grey's, big, screen, -, thursda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8746</td>\n",
       "      <td>@ my pleasure patrick....hope you are well!</td>\n",
       "      <td>7</td>\n",
       "      <td>[@, pleasure, patrick....hope, well!]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              tweet  word_count  \\\n",
       "0  8746           @ let's try and catch up live next week!           9   \n",
       "1  8746  going to watch grey's on the big screen - thur...          11   \n",
       "2  8746        @ my pleasure patrick....hope you are well!           7   \n",
       "\n",
       "                                              tokens  \n",
       "0          [@, let's, try, catch, live, next, week!]  \n",
       "1  [going, watch, grey's, big, screen, -, thursda...  \n",
       "2              [@, pleasure, patrick....hope, well!]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a word count per sentence column\n",
    "def word_count(sentence):\n",
    "    return len(sentence.split())\n",
    "    \n",
    "df['word_count'] = df['tweet'].apply(word_count)\n",
    "df.head(3)\n",
    "\n",
    "# # Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "    # stop_words = set(stopwords.words('english'))\n",
    "# df['tweet_without_stopwords'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             @ let's try and catch up live next week!\n",
       "1    going to watch grey's on the big screen - thur...\n",
       "2          @ my pleasure patrick....hope you are well!\n",
       "3    @ hi there! been traveling a lot and lots more...\n",
       "4    rt @ looking to drink clean & go green? purcha...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-processing the raw tweets\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def processTweet(tweet):\n",
    "    # Removing http links from the tweet\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    # Removing 'handle' keyword from the tweets\n",
    "    tweet = re.sub(r\"handle\", \"\", tweet)\n",
    "    # To lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # tweet = (lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "    tweet = ''.join(c for c in tweet if c <= '\\uFFFF') \n",
    "    return tweet\n",
    "\n",
    "# clean dataframe's text column\n",
    "df['tweet'] = df['tweet'].apply(processTweet)\n",
    "# preview some cleaned tweets\n",
    "df['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@', 141587),\n",
       " ('the', 125117),\n",
       " ('to', 98094),\n",
       " ('a', 77160),\n",
       " ('i', 70171),\n",
       " ('and', 54093),\n",
       " ('for', 52677),\n",
       " ('of', 51519),\n",
       " ('in', 50792),\n",
       " ('is', 45305)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common words in twitter dataset\n",
    "all_words = []\n",
    "for line in list(df['tweet']):\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        all_words.append(word.lower())\n",
    "Counter(all_words).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8746</td>\n",
       "      <td>@ let's try and catch up live next week!</td>\n",
       "      <td>9</td>\n",
       "      <td>[@, let's, try, catch, live, next, week!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8746</td>\n",
       "      <td>going to watch grey's on the big screen - thur...</td>\n",
       "      <td>11</td>\n",
       "      <td>[going, watch, grey's, big, screen, -, thursda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8746</td>\n",
       "      <td>@ my pleasure patrick....hope you are well!</td>\n",
       "      <td>7</td>\n",
       "      <td>[@, pleasure, patrick....hope, well!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8746</td>\n",
       "      <td>@ hi there! been traveling a lot and lots more...</td>\n",
       "      <td>27</td>\n",
       "      <td>[@, hi, there!, traveling, lot, lots, come, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8746</td>\n",
       "      <td>rt @ looking to drink clean &amp; go green? purcha...</td>\n",
       "      <td>19</td>\n",
       "      <td>[rt, @, looking, drink, clean, &amp;, go, green?, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              tweet  word_count  \\\n",
       "0  8746           @ let's try and catch up live next week!           9   \n",
       "1  8746  going to watch grey's on the big screen - thur...          11   \n",
       "2  8746        @ my pleasure patrick....hope you are well!           7   \n",
       "3  8746  @ hi there! been traveling a lot and lots more...          27   \n",
       "4  8746  rt @ looking to drink clean & go green? purcha...          19   \n",
       "\n",
       "                                              tokens  \n",
       "0          [@, let's, try, catch, live, next, week!]  \n",
       "1  [going, watch, grey's, big, screen, -, thursda...  \n",
       "2              [@, pleasure, patrick....hope, well!]  \n",
       "3  [@, hi, there!, traveling, lot, lots, come, ne...  \n",
       "4  [rt, @, looking, drink, clean, &, go, green?, ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize helper function\n",
    "def text_process(raw_text):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "#     # Check characters to see if they are in punctuation\n",
    "#     nopunc = [char for char in list(raw_text) if char not in string.punctuation]\n",
    "#     # Join the characters again to form the string.\n",
    "#     nopunc = ''.join(nopunc)\n",
    "    raw_text = ''.join(raw_text) \n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in raw_text.lower().split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "# def remove_words(word_list):\n",
    "#     remove = ['paul','ryan','...','“','”','’','…','ryan’']\n",
    "#     return [w for w in word_list if w not in remove]\n",
    "# -------------------------------------------\n",
    "# tokenize message column and create a column for tokens\n",
    "df = df.copy()\n",
    "df['tokens'] = df['tweet'].apply(text_process) # tokenize style 1\n",
    "# df_paulry['no_pauls'] = df_paulry['tokens'].apply(remove_words) #tokenize style 2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324183\n"
     ]
    }
   ],
   "source": [
    "# vectorize\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(df['tweet'])\n",
    "# print total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (328195, 324183)\n",
      "Amount of Non-Zero occurences:  2852457\n"
     ]
    }
   ],
   "source": [
    "# # example of vectorized text\n",
    "# sample_tweet = df['tweet'][123]\n",
    "# print(sample_tweet)\n",
    "# print('\\n')\n",
    "# # vector representation\n",
    "# bow_sample = bow_transformer.transform([sample_tweet])\n",
    "# print(bow_sample)\n",
    "# print('\\n')\n",
    "\n",
    "# transform the entire DataFrame of messages\n",
    "messages_bow = bow_transformer.transform(df['tweet'])\n",
    "# check out the bag-of-words counts for the entire corpus as a large sparse matrix\n",
    "print('Shape of Sparse Matrix: ', messages_bow.shape)\n",
    "print('Amount of Non-Zero occurences: ', messages_bow.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328195, 324183)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "\n",
    "# to transform the entire bag-of-words corpus\n",
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d269d52ad250>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# uncomment below to train on a larger dataset but it's very slow for a slower machine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['id'], test_size=0.2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# create pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Run Train Data Through Pipeline analyzer=text_process\n",
    "# uncomment below to train on a larger dataset but it's very slow for a slower machine.\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['id'], test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet'][:50000], df['id'][:50000], test_size=0.2)\n",
    "\n",
    "# create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(strip_accents='ascii',\n",
    "                            stop_words='english',\n",
    "                            lowercase=True)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "# this is where we define the values for GridSearchCV to iterate over\n",
    "parameters = {'bow__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'classifier__alpha': (1e-2, 1e-3),\n",
    "             }\n",
    "\n",
    "# do 10-fold cross validation for each of the 6 possible combinations of the above params\n",
    "grid = GridSearchCV(pipeline, cv=10, param_grid=parameters, verbose=1)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"\\nBest Model: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "print('\\n')\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"Mean: %f Stdev:(%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.443\n",
      "\n",
      "\n",
      "confusion matrix: \n",
      " [[8 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 6 0]\n",
      " [0 0 0 ... 0 0 9]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          28       0.42      0.53      0.47        15\n",
      "         483       1.00      0.20      0.33         5\n",
      "         484       0.00      0.00      0.00         1\n",
      "         564       0.33      0.30      0.32        10\n",
      "         572       0.88      1.00      0.94        15\n",
      "         578       1.00      0.40      0.57         5\n",
      "         638       0.67      0.57      0.62         7\n",
      "         643       1.00      0.22      0.36         9\n",
      "         713       0.14      0.50      0.22         2\n",
      "         766       0.33      0.17      0.22         6\n",
      "         841       0.75      0.50      0.60         6\n",
      "         852       0.31      0.36      0.33        14\n",
      "         982       0.40      0.40      0.40         5\n",
      "        1017       0.45      0.61      0.52        23\n",
      "        1116       0.00      0.00      0.00         4\n",
      "        1121       0.28      0.38      0.32        13\n",
      "        1163       0.79      0.65      0.71        23\n",
      "        1173       1.00      0.67      0.80         9\n",
      "        1224       1.00      0.43      0.60         7\n",
      "        1247       0.00      0.00      0.00         6\n",
      "        1293       0.78      0.70      0.74        10\n",
      "        1431       0.00      0.00      0.00         1\n",
      "        1533       1.00      1.00      1.00         6\n",
      "        1613       0.50      0.50      0.50         8\n",
      "        1623       0.00      0.00      0.00         6\n",
      "        1634       0.50      0.20      0.29         5\n",
      "        1732       0.38      0.75      0.50         4\n",
      "        1763       1.00      0.50      0.67         4\n",
      "        1822       0.67      0.50      0.57         4\n",
      "        1854       0.50      0.57      0.53         7\n",
      "        1962       0.25      0.17      0.20        12\n",
      "        2143       0.71      0.83      0.77         6\n",
      "        2260       0.17      0.40      0.24         5\n",
      "        2423       0.38      0.50      0.43         6\n",
      "        2465       0.91      0.91      0.91        11\n",
      "        2504       0.00      0.00      0.00         5\n",
      "        2582       0.00      0.00      0.00        10\n",
      "        2608       0.00      0.00      0.00         4\n",
      "        2764       0.44      0.50      0.47         8\n",
      "        2771       0.17      0.14      0.15         7\n",
      "        2865       0.33      0.12      0.18         8\n",
      "        2886       0.33      0.12      0.17        17\n",
      "        2985       0.00      0.00      0.00         3\n",
      "        3039       0.00      0.00      0.00         4\n",
      "        3129       0.00      0.00      0.00         3\n",
      "        3417       0.62      0.62      0.62         8\n",
      "        3508       0.25      0.14      0.18         7\n",
      "        3539       0.23      0.25      0.24        12\n",
      "        3815       0.33      0.20      0.25         5\n",
      "        3887       1.00      1.00      1.00         5\n",
      "        4310       0.67      0.29      0.40         7\n",
      "        4375       0.00      0.00      0.00         5\n",
      "        4450       0.25      0.50      0.33         2\n",
      "        4615       0.38      0.21      0.27        14\n",
      "        4772       0.67      0.80      0.73         5\n",
      "        4897       0.17      0.50      0.25         4\n",
      "        4937       0.60      0.55      0.57        11\n",
      "        5012       0.56      0.67      0.61        15\n",
      "        5050       0.44      0.61      0.51        18\n",
      "        5187       0.00      0.00      0.00         5\n",
      "        5198       0.00      0.00      0.00         5\n",
      "        5337       0.00      0.00      0.00         8\n",
      "        5373       0.33      0.08      0.13        12\n",
      "        5455       0.71      0.62      0.67         8\n",
      "        5478       0.43      0.33      0.38         9\n",
      "        5498       0.89      1.00      0.94         8\n",
      "        5607       1.00      0.44      0.62         9\n",
      "        5654       0.14      0.18      0.16        17\n",
      "        5822       0.17      0.50      0.25         2\n",
      "        5850       0.00      0.00      0.00         9\n",
      "        5938       0.90      0.87      0.89        31\n",
      "        6086       0.25      0.33      0.29         3\n",
      "        6136       0.40      0.67      0.50         3\n",
      "        6140       0.50      0.33      0.40         3\n",
      "        6205       0.00      0.00      0.00         6\n",
      "        6312       0.30      0.33      0.32         9\n",
      "        6385       0.00      0.00      0.00         3\n",
      "        6578       0.33      0.17      0.22         6\n",
      "        6796       0.62      0.71      0.67         7\n",
      "        6847       0.62      0.83      0.71         6\n",
      "        7049       0.71      0.56      0.63         9\n",
      "        7070       0.20      0.25      0.22         4\n",
      "        7087       0.50      1.00      0.67         2\n",
      "        7123       0.75      1.00      0.86         6\n",
      "        7254       0.80      1.00      0.89        20\n",
      "        7315       1.00      1.00      1.00         4\n",
      "        7477       1.00      0.40      0.57         5\n",
      "        7482       0.16      0.41      0.23        32\n",
      "        7593       0.75      0.38      0.50         8\n",
      "        7685       0.60      0.30      0.40        10\n",
      "        7736       0.20      0.23      0.21        39\n",
      "        7838       0.31      0.57      0.40         7\n",
      "        8129       0.50      0.11      0.18         9\n",
      "        8523       0.46      0.86      0.60        14\n",
      "        8573       0.50      0.33      0.40         6\n",
      "        8595       0.22      0.43      0.29        14\n",
      "        8746       0.33      0.38      0.35        16\n",
      "        8901       0.33      0.12      0.18         8\n",
      "        9060       0.40      1.00      0.57         2\n",
      "        9148       0.55      0.85      0.67        13\n",
      "        9220       0.00      0.00      0.00         7\n",
      "        9311       0.12      0.09      0.11        11\n",
      "        9354       0.67      0.40      0.50         5\n",
      "        9442       0.00      0.00      0.00         8\n",
      "        9595       0.50      0.30      0.37        10\n",
      "        9629       0.58      0.68      0.63        31\n",
      "        9661       1.00      0.40      0.57        10\n",
      "        9679       0.67      0.50      0.57         4\n",
      "        9765       0.36      0.36      0.36        11\n",
      "        9786       0.45      0.29      0.36        17\n",
      "        9846       0.00      0.00      0.00         5\n",
      "        9968       0.75      0.75      0.75         8\n",
      "        9976       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.44      1000\n",
      "   macro avg       0.44      0.41      0.40      1000\n",
      "weighted avg       0.47      0.44      0.43      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# save best model to current working directory\n",
    "joblib.dump(grid, \"twitter_sentiment.pkl\")\n",
    "\n",
    "# load from file and predict using the best configs found in the CV step\n",
    "model_NB = joblib.load(\"twitter_sentiment.pkl\" )\n",
    "\n",
    "# get predictions from best model above\n",
    "y_preds = model_NB.predict(X_test)\n",
    "print('accuracy score: ',accuracy_score(y_test, y_preds))\n",
    "print('\\n')\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test,y_preds))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
